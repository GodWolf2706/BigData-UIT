{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8560ca",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f332c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 23:49:18 WARN Utils: Your hostname, godwolf-2-7 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/05/20 23:49:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/20 23:49:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# thêm lớp SparkSession từ gói pyspark.sql dể sử dụng các chức năng như tạo dataframe, thao tác trên dữ liệu\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# tạo một đối tượng SparkSession bằng phương thức \"builder\", chạy trên một luồng cục bộ\n",
    "# ứng dụng được đặt tên là \"SparkMLLib_DecisionTree\"\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkMLLib_DecisionTree\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a732dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/20 23:49:27 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chỉ định \"print\" trong file sẽ được sử dụng theo Python3.x\n",
    "from __future__ import print_function\n",
    "\n",
    "# thêm các lớp Pipeline, DecisionTreeClassifier, StringIndexer, VectorIndexer, MulticlassClassificationEvaluator từ gói pyspark.ml \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# tạo 1 dataframe từ dữ liệu trong tệp tin có định dạng LibSVM\n",
    "data = spark.read.format(\"libsvm\").load(\"/home/godwolf/Downloads/spark-3.5.1-bin-hadoop3/python/TH4/TH6_Attachments/sample_libsvm_data.txt\")\n",
    "\n",
    "# hiển thị một số hàng đầu tiên của dataframe\n",
    "data.show()\n",
    "\n",
    "# đếm số lượng hàng trong dataframe\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a74432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# tạo đối tượng \"StringIndexer\" để chuyển đổi cột label từ chuỗi thành số nguyên, cột đàu ra được đặt tên là indexedLabel \n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# tạo đối tượng \"VectorIndexer\" để xác định và chuyển đổi cột featuré thành dạng số nguyên, cột đầu ra được đặt tên là indexedFeatures\n",
    "# maxCategories để xác định rằng nếu một đặc trưng ít hơn 4 danh mục thì sẽ được xem là 1 đặc trưng và được đổi thành số nguyên\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f457434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.show()\n",
    "\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f86a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 13:>                                                         (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# chia dữ liệu thành 2 phần: tập huấn luyện và tâp kiểm tra. 70% giữ để huấn luyện và 30% giữ để kiểm tra\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# tạo đối tượng DecisionTreeClassifier để định nghĩa mô hình cây quyết định với giá trị đầu vào dự đoán là indexedLabel, indexedFeatures\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# tạo đối tượng Pipeline xử lý dữ liệu và mô hình hóa \n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# huấn luyện mô hình trên dữ liệu huấn luyện trainingData, hàm fit() sẽ thực hiện các công đoạn trong Pineline\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c174692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|(692,[98,99,100,1...|\n",
      "|       1.0|         1.0|(692,[121,122,123...|\n",
      "|       1.0|         1.0|(692,[123,124,125...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[126,127,128...|\n",
      "|       1.0|         1.0|(692,[126,127,128...|\n",
      "|       1.0|         1.0|(692,[126,127,128...|\n",
      "|       1.0|         1.0|(692,[151,152,153...|\n",
      "|       1.0|         1.0|(692,[153,154,155...|\n",
      "|       0.0|         1.0|(692,[154,155,156...|\n",
      "|       1.0|         1.0|(692,[155,156,180...|\n",
      "|       1.0|         1.0|(692,[234,235,237...|\n",
      "|       0.0|         0.0|(692,[100,101,102...|\n",
      "|       0.0|         0.0|(692,[123,124,125...|\n",
      "|       0.0|         0.0|(692,[124,125,126...|\n",
      "|       0.0|         0.0|(692,[125,126,127...|\n",
      "|       0.0|         0.0|(692,[125,126,153...|\n",
      "|       0.0|         0.0|(692,[126,127,128...|\n",
      "|       0.0|         0.0|(692,[127,128,129...|\n",
      "|       0.0|         0.0|(692,[128,129,130...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error = 0.0740741 \n"
     ]
    }
   ],
   "source": [
    "# sử dụng mô hình đã được huấn luyện để thực hiện dự đoán trên dữ liệu kiểm tra testData\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# chọn 3 cột \"prediction\", \"indexedLabel\", \"features\" từ dataframe và hiển thị các giá trị của 3 cột\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show()\n",
    "\n",
    "# tạo đối tượng MulticlassClassificationEvaluator để đánh giá hiệu suất của mô hình\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# tính toán độ chính xác của mô hình\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# hiển thị độ lỗi trên tập dữ liệu \n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fd0a4",
   "metadata": {},
   "source": [
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03180cc4",
   "metadata": {},
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a08112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 00:15:46 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark_1 = SparkSession.builder.master(\"local[*]\").appName(\"SparkMLLib_KMeans\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8617b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 00:18:28 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "|  5.0|(3,[0,1,2],[9.2,9...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Loads data.\n",
    "dataset_1 = spark_1.read.format(\"libsvm\").load(\"/home/godwolf/Downloads/spark-3.5.1-bin-hadoop3/python/TH4/TH6_Attachments/sample_kmeans_data.txt\")\n",
    "\n",
    "dataset_1.show()\n",
    "\n",
    "dataset_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcea4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo đối tượng KMeans, thiết lập số lượng cụm cần phân là 2, thiết lập seed=1 để đảm bảo tính nhất quán của kết quả\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "\n",
    "# huấn luyện mô hình trên dữ liệu dataset_1\n",
    "model = kmeans.fit(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d8f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9997530305375207\n"
     ]
    }
   ],
   "source": [
    "# sử dụng mô hình kmean đã huấn luyện để dự đoán cụm cho dữ liệ\n",
    "predictions = model.transform(dataset_1)\n",
    "\n",
    "# đánh giá chất lượng việc phân cụm\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "# tính toán chỉ số silhouette để đánh giá chát lượng của việc phân cụm\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "\n",
    "# in ra đoạn text với giá trị của chỉ số silhouette\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d49afa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[9.1 9.1 9.1]\n",
      "[0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "# hiển thị các trung tâm của các cụm\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a1bcd",
   "metadata": {},
   "source": [
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fce4c1",
   "metadata": {},
   "source": [
    "# NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b4ab91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 00:31:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark_2 = SparkSession.builder.master(\"local[*]\").appName(\"SparkMLLib_NaiveBayes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad64c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/21 00:35:01 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\").load(\"/home/godwolf/Downloads/spark-3.5.1-bin-hadoop3/python/TH4/TH6_Attachments/sample_libsvm_data.txt\")\n",
    "\n",
    "data.show()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f658f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# chia dữ liệu thành 2 tập dữ liệu: tập huân luyện (60%) và tập kiểm tra (40%)\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "\n",
    "# gán tập dữ liêu đầu tiên trong danh sách splits cho biến train\n",
    "train = splits[0]\n",
    "\n",
    "# gán tập dữ liệu thứ hai trong danh sách splits cho biến test\n",
    "test = splits[1]\n",
    "\n",
    "# định nghĩa mô hình NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# huấn luyện mô hình trên tập dữ liệu huấn luyện\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57714e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|label|            features|       rawPrediction|probability|prediction|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[-172664.79564650...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[98,99,100,1...|[-176279.15054306...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[-189600.55409526...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-274673.88337431...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-183393.03869049...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[-256992.48807619...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[-210411.53649773...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-170627.63616681...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-212157.96750469...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-183253.80108550...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[-246528.93739632...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[-158348.34683571...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-210229.50765957...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-242985.16248889...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-94622.933454005...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-266465.39689814...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-144989.71469229...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-283834.57437738...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|[-155256.59399829...|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|[-147726.11958982...|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# sử dụng mô hình naivebayes đã được huấn luyện để dự đoán cho dữ liệu trong tập kiểm tra\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# hiển thị kết quả sau khi dự đoán\n",
    "predictions.show()\n",
    "\n",
    "# đánh giá hiệu suất của mô hình\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# tính toán độ chính xác của mô hình\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# in ra đoạn text và chỉ số độ chính xác của mô hình\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c0d85",
   "metadata": {},
   "source": [
    "# ================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae2be6",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05eca8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_3 = SparkSession.builder.master(\"local[*]\").appName(\"SparkMLLib_TFIDF\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "991a17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c8ce65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo 1 dataframe từ dữ liệu văn bản\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f848a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tạo đối tượng tokenizer với giá trị đầu vào là giá trị của cột sentence và dữ liệu đầu ra sẽ được đưa vào cột words\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "\n",
    "# sử dụng tokenizer đã được tạo để biến đổi dữ liệu văn bản trong dataframe sau đó lưu vào wordsData\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "\n",
    "# hiển thị kết quả là dữ liệu ban đầu với thêm cột words chứa các từ đã được tách ra \n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a05013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|            sentence|               words|         rawFeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|(20,[6,8,13,16],[...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|(20,[0,2,7,13,15,...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|(20,[3,4,6,11,19]...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tạo đối tượng HashingTF với giá trị đầu vào là giá trị trong cột \"words\" đã được tách chữ, giá trị đầu ra sẽ được lưu vào cột rawFeatures\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "\n",
    "# sử dụng hashingTF đã được tạo để biến đổi dữ liệu trong wordsData sau đó lưu két quả vào biến featurizedData\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "# hiển thị kết quả là dữ liệu wordsData với thêm cột mới chứa vector đặc trưng  \n",
    "featurizedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf9e4601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# tạo đối tượng IDF với giá trị đầu vào là giá trị của cột rawFeatures và giá trị đầu ra sẽ lưu vào côt features\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# sử dụng đối tượng idf đã được tạo để huấn luyện mô hình IDF trên tập dữ liệu featurizedData \n",
    "idfModel = idf.fit(featurizedData)\n",
    "\n",
    "# sử dụng mô hình idf đã được huấn luyện để biến đổi dữ liệu trong featurizedData\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9b9061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(20,[6,8,13,16],[...|\n",
      "|  0.0|(20,[0,2,7,13,15,...|\n",
      "|  1.0|(20,[3,4,6,11,19]...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hiển thị cột label và cột features trong dataframe rescaledData\n",
    "rescaledData.select(\"label\", \"features\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
